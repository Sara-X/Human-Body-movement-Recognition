{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pdb\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "torch.set_printoptions(linewidth=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 200   # 根据实际情况决定\n",
    "num_moves = 2811   # =动作数量=文件数量\n",
    "key_points = ['nose','leftEye','rightEye','leftEar','rightEar','leftShoulder','rightShoulder','leftElbow','rightElbow','leftWrist','rightWrist','leftHip','rightHip','leftKnee','rightKnee','leftAnkle','rightAnkle']\n",
    "\n",
    "class JointsDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.moves = []\n",
    "        for i in range(num_moves):\n",
    "            with open('./train_data/' + 'train_'+ str(i) + '.json') as f:  # 根据具体文件名格式改\n",
    "                l = json.load(f)\n",
    "                self.moves.append(l)\n",
    "        \n",
    "        # for i in range(num_moves):\n",
    "        #     with open('./train_data/' + str(i) + '.txt') as f:\n",
    "        #        content = f.read()\n",
    "        #        frames = content.splitlines()\n",
    "        #        self.moves.append(frames)\n",
    "        \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        move = self.moves[index]\n",
    "        y1 = torch.empty(1, dtype=torch.long)  #label\n",
    "        y1[0] = int(move[0])\n",
    "        frams_list = []\n",
    "        for frame in move[1:]:  # 处理json文件中的list和dict，因为没有data就还没测试过，可能有错\n",
    "            if frame == {}:\n",
    "                continue\n",
    "            joints = []\n",
    "            for key in key_points:\n",
    "                if (str(frame[key]) == '0'):\n",
    "                    x = y = 0\n",
    "                else:\n",
    "                    coordinates = str(frame[key]).split(',')\n",
    "                    x,y = float(coordinates[0]),float(coordinates[1])\n",
    "                joints.append(x)\n",
    "                joints.append(y)\n",
    "            frams_list.append(joints)\n",
    "        x = torch.Tensor(frams_list)\n",
    "        return x, y1\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.moves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[723.8028,  11.5272, 638.1023,  11.7085, 738.8450,   5.7470, 633.5067,  57.9745, 741.4124,  33.8518, 572.4636, 171.7782, 934.2894, 146.0907, 523.0648, 362.9948, 973.2326, 338.8710, 536.9642,\n",
      "         497.8299,   0.0000,   0.0000, 663.7974, 490.9104, 889.4023, 470.6810,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "        [641.3535,  21.0259,   0.0000,   0.0000,   0.0000,   0.0000, 553.2728,  62.9508, 642.6283,  39.4102, 503.8728, 163.2738, 809.2134, 143.9737, 425.8270, 339.2299, 888.9832, 288.4796, 449.0788,\n",
      "         394.4255, 905.0687, 438.3098, 581.9385, 456.2242, 780.7005, 465.2279,   0.0000,   0.0000,   0.0000,   0.0000, 932.4575, 448.8194, 928.3540, 449.7087],\n",
      "        [471.4317, 149.4662, 467.7706, 134.5160,   0.0000,   0.0000, 478.3094, 134.2590, 522.4439, 134.5417, 451.6573, 197.5856, 613.6993, 174.2105, 427.1194, 293.4438, 672.8166, 252.5925, 431.4388,\n",
      "         362.2605, 666.6017, 366.4981, 500.8249, 375.9950, 614.2695, 372.0779, 503.7657, 470.4887, 649.7523, 471.5130,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "        [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000, 475.2244, 130.5050, 512.0507, 113.9532, 437.8689, 184.6555, 583.7535, 171.5314, 421.5580, 266.3825, 637.0671, 250.8051, 453.4242,\n",
      "         299.3655, 636.5534, 321.9898, 475.7079, 365.3321, 576.8120, 351.7661, 502.6194, 465.5149, 684.9786, 446.9875,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "        [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000, 489.6660, 145.4307, 523.4521, 139.3517, 466.2115, 190.8461, 558.7826, 184.1776, 442.6800, 260.8217, 599.2708, 253.7672, 449.0654,\n",
      "         302.3570, 609.5479, 286.3418, 494.4624, 307.1572, 553.6517, 315.1558, 501.6703, 406.1813, 555.5046, 397.7145, 518.6375, 465.0608, 565.0853, 461.7238],\n",
      "        [502.4799, 166.7885, 498.5667, 158.2584,   0.0000,   0.0000, 493.3443, 162.3909, 535.1092, 159.4750, 486.0833, 192.3877, 558.5972, 190.4713, 458.4960, 241.1624, 588.4576, 240.6946, 466.2770,\n",
      "         257.9102, 607.5930, 302.5781, 502.3288, 301.2684, 556.1287, 304.2624, 513.4711, 379.6956, 555.6080, 380.7823, 514.4237, 438.3217, 562.2261, 439.9099],\n",
      "        [510.7447, 170.4241, 515.8204, 158.0525, 525.1678, 160.0262, 517.4822, 164.3189, 547.1381, 161.9958, 505.3817, 201.3138, 569.0689, 193.3125, 478.4234, 246.4260, 599.5869, 249.0118, 483.0526,\n",
      "         286.1085, 613.9714, 300.2978, 519.2065, 299.9063, 568.3289, 308.1552, 523.8398, 380.2158, 567.8666, 374.9282, 525.5967, 435.5253, 565.3094, 436.6584],\n",
      "        [534.2856, 159.4801,   0.0000,   0.0000,   0.0000,   0.0000, 527.2546, 162.7119, 556.3138, 164.9103, 514.1752, 194.8790, 574.4386, 184.1125, 488.1381, 233.6506, 596.7502, 239.8975, 493.2490,\n",
      "         255.9462, 603.9067, 265.1654, 524.9487, 268.4766, 567.5458, 267.8538, 537.8379, 333.1693, 570.5328, 327.1897, 550.5035, 398.0688, 578.4415, 389.5559],\n",
      "        [548.0075, 174.8703, 544.3858, 167.2986, 556.7264, 162.3644, 537.7708, 163.2924, 571.8859, 172.4956, 520.1303, 194.8381, 590.7897, 195.4360, 499.0688, 235.7658, 609.0790, 237.2972, 515.9707,\n",
      "         260.9881, 611.5744, 264.6534, 534.3828, 266.9998, 573.5135, 268.6478, 524.5815, 316.1508, 580.2947, 318.1035, 545.8152, 390.8705, 591.1710, 376.8996],\n",
      "        [627.0879, 185.8037,   0.0000,   0.0000, 605.5499, 190.3748, 567.1557, 179.9130, 595.2056, 188.3250, 530.1317, 200.0439, 580.8405, 202.4605, 517.9422, 240.4785, 610.2783, 244.1521, 543.3191,\n",
      "         257.8542, 634.5725, 239.8838, 535.2049, 265.7452, 572.3393, 268.9780, 544.1414, 322.1127, 600.0587, 314.9345, 547.2518, 368.9507, 613.9579, 373.2186],\n",
      "        [627.0879, 185.8037,   0.0000,   0.0000, 605.5499, 190.3748, 567.1557, 179.9130, 595.2056, 188.3250, 530.1317, 200.0439, 580.8405, 202.4605, 517.9422, 240.4785, 610.2783, 244.1521, 543.3191,\n",
      "         257.8542, 634.5725, 239.8838, 535.2049, 265.7452, 572.3393, 268.9780, 544.1414, 322.1127, 600.0587, 314.9345, 547.2518, 368.9507, 613.9579, 373.2186]]), tensor([2]))\n",
      "<built-in method size of Tensor object at 0x128000870>\n",
      "9\n",
      "2811\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "trn_ds = JointsDataset()\n",
    "print(trn_ds[4])\n",
    "print(trn_ds[0][0].size)\n",
    "print(len(trn_ds[1][0]))\n",
    "print(len(trn_ds))\n",
    "print(len(key_points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RNN,self).__init__()\n",
    "        # TO DO\n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "        self.in_size = 34   # =一帧坐标的关键点数量\n",
    "        self.hidden_size = 100   #随便取，比in size大一截就行，因为posenet只有十几个点，最好改成100左右\n",
    "        self.out_size = 3   # label数量\n",
    "        self.lstm = nn.LSTM(self.in_size, self.hidden_size)\n",
    "        self.h2o = nn.Linear(self.hidden_size,self.out_size)\n",
    "       \n",
    "    \n",
    "    def forward(self,x):\n",
    "        # TO DO\n",
    "        # YOUR CODE HERE\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        out_space = self.h2o(lstm_out)\n",
    "        #y_pred = F.softmax(out_space)\n",
    "        return out_space\n",
    "        \n",
    "        \n",
    "        # x = x.view(self.in_size)\n",
    "        # waa_a = self.h2h(a)\n",
    "        # wax_x = self.i2h(x)\n",
    "        # new_a = torch.tanh(waa_a + wax_x)\n",
    "        # y = self.h2o(new_a)\n",
    "        # return new_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility for getting prediction accuracy\n",
    "def get_correct(y_pred, y):\n",
    "    # find the prediction class label\n",
    "    _ ,pred_class = y_pred.max(dim=1)\n",
    "    return pred_class == y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "trn_ds = JointsDataset()\n",
    "trn_dl = DataLoader(trn_ds, batch_size=1, shuffle=True)\n",
    "\n",
    "def train(trn_ds, trn_dl, epochs=1):\n",
    "    # Create a new model, loss_fn and optimizer.\n",
    "    model = RNN()\n",
    "    # Use cross entropy loss\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(),lr=0.0001) # lr: learning rate，学习速度\n",
    "    h_prev = torch.zeros((1,hidden_size))\n",
    "    max_train_accu = 0\n",
    "    max_vali_accu = 0\n",
    "    \n",
    "    train = []\n",
    "    vali = []\n",
    "    for move_num, (x,y) in enumerate(trn_dl):   # 取80%为training set, 20%为validation set\n",
    "        dice = random.random()\n",
    "        if dice <= 0.8:\n",
    "            train.append([x,y])\n",
    "        else:\n",
    "            vali.append([x,y])\n",
    "        \n",
    "        \n",
    "    for e in range(1, epochs+1):\n",
    "        print(f'{\"-\"*20} Epoch {e} {\"-\"*20}')\n",
    "        #count = 0\n",
    "        train_count = num_moves*0.8\n",
    "        vali_count = num_moves*0.2\n",
    "        train_num_correct = 0\n",
    "        vali_num_correct = 0\n",
    "        train_loss = 0\n",
    "        vali_loss = 0\n",
    "        \n",
    "        for (x,y) in train:\n",
    "            #if count <= train_count:\n",
    "                #count += 1\n",
    "                #print('----',count,'----')\n",
    "                y = y.view(y.shape[1])\n",
    "                model.train()\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "              \n",
    "                y_pred = model.forward(x)[0][-1]\n",
    "                y_pred = y_pred.view(1,len(y_pred))\n",
    "                label = y.view(1)\n",
    "                #print('y_pred', y_pred)\n",
    "                #print('label',label)\n",
    "                l = loss_fn(y_pred, label)\n",
    "                train_loss += l   \n",
    "                correct = get_correct(y_pred,label)\n",
    "                if correct == True:\n",
    "                    train_num_correct += 1\n",
    "                #print('train num of correct',train_num_correct)\n",
    "                l.backward(retain_graph=True)\n",
    "        \n",
    "                # Clip your gradients\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
    "        \n",
    "                # Update parameters\n",
    "                optimizer.step()\n",
    "                # print('loss',loss)\n",
    "        for (x,y) in vali:\n",
    "                #print('----',count,'----')\n",
    "                #count+=1\n",
    "                y = y.view(y.shape[1])\n",
    "                y_pred = model.forward(x)[0][-1]\n",
    "                y_pred = y_pred.view(1,len(y_pred))\n",
    "                label = y.view(1)\n",
    "                #print('y_pred', y_pred)\n",
    "                #print('label',label)\n",
    "                l = loss_fn(y_pred, label)\n",
    "                vali_loss += l   \n",
    "                correct = get_correct(y_pred,label)\n",
    "                if correct == True:\n",
    "                    vali_num_correct += 1\n",
    "                #print('vali num of correct',vali_num_correct)\n",
    "        \n",
    "        train_accuracy = train_num_correct/len(train)\n",
    "        vali_accuracy = vali_num_correct/len(vali)\n",
    "        print('TRAIN ACCURACY',train_accuracy,'VALIDATION ACCURACY', vali_accuracy)\n",
    "        #if train_accuracy > max_train_accu and vali_accuracy > max_vali_accu:\n",
    "        #      torch.save(model.state_dict(),PATH)\n",
    "        PATH = 'data0829MAX '+str(e)+' .pth'\n",
    "        torch.save(model.state_dict(),PATH)   \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Epoch 1 --------------------\n",
      "TRAIN ACCURACY 0.5406376290974405 VALIDATION ACCURACY 0.6198630136986302\n",
      "-------------------- Epoch 2 --------------------\n",
      "TRAIN ACCURACY 0.5711719802424786 VALIDATION ACCURACY 0.6215753424657534\n",
      "-------------------- Epoch 3 --------------------\n",
      "TRAIN ACCURACY 0.5832959137853615 VALIDATION ACCURACY 0.6335616438356164\n",
      "-------------------- Epoch 4 --------------------\n",
      "TRAIN ACCURACY 0.5859901212393355 VALIDATION ACCURACY 0.6267123287671232\n",
      "-------------------- Epoch 5 --------------------\n",
      "TRAIN ACCURACY 0.5877862595419847 VALIDATION ACCURACY 0.6267123287671232\n",
      "-------------------- Epoch 6 --------------------\n",
      "TRAIN ACCURACY 0.5927256398742703 VALIDATION ACCURACY 0.636986301369863\n",
      "-------------------- Epoch 7 --------------------\n",
      "TRAIN ACCURACY 0.5976650202065559 VALIDATION ACCURACY 0.6438356164383562\n",
      "-------------------- Epoch 8 --------------------\n",
      "TRAIN ACCURACY 0.5999101930848675 VALIDATION ACCURACY 0.6404109589041096\n",
      "-------------------- Epoch 9 --------------------\n",
      "TRAIN ACCURACY 0.6026044005388415 VALIDATION ACCURACY 0.6421232876712328\n",
      "-------------------- Epoch 10 --------------------\n",
      "TRAIN ACCURACY 0.6084418500224518 VALIDATION ACCURACY 0.6421232876712328\n",
      "-------------------- Epoch 11 --------------------\n",
      "TRAIN ACCURACY 0.6120341266277504 VALIDATION ACCURACY 0.6455479452054794\n",
      "-------------------- Epoch 12 --------------------\n",
      "TRAIN ACCURACY 0.614279299506062 VALIDATION ACCURACY 0.6438356164383562\n",
      "-------------------- Epoch 13 --------------------\n",
      "TRAIN ACCURACY 0.6133812303547374 VALIDATION ACCURACY 0.6455479452054794\n",
      "-------------------- Epoch 14 --------------------\n",
      "TRAIN ACCURACY 0.6147283340817243 VALIDATION ACCURACY 0.648972602739726\n",
      "-------------------- Epoch 15 --------------------\n",
      "TRAIN ACCURACY 0.6151773686573866 VALIDATION ACCURACY 0.648972602739726\n",
      "-------------------- Epoch 16 --------------------\n",
      "TRAIN ACCURACY 0.6165244723843736 VALIDATION ACCURACY 0.648972602739726\n",
      "-------------------- Epoch 17 --------------------\n",
      "TRAIN ACCURACY 0.6174225415356982 VALIDATION ACCURACY 0.648972602739726\n",
      "-------------------- Epoch 18 --------------------\n",
      "TRAIN ACCURACY 0.616973506960036 VALIDATION ACCURACY 0.648972602739726\n",
      "-------------------- Epoch 19 --------------------\n",
      "TRAIN ACCURACY 0.6174225415356982 VALIDATION ACCURACY 0.648972602739726\n",
      "-------------------- Epoch 20 --------------------\n",
      "TRAIN ACCURACY 0.6290974405029187 VALIDATION ACCURACY 0.6643835616438356\n",
      "-------------------- Epoch 21 --------------------\n",
      "TRAIN ACCURACY 0.6470588235294118 VALIDATION ACCURACY 0.6695205479452054\n",
      "-------------------- Epoch 22 --------------------\n",
      "TRAIN ACCURACY 0.6466097889537494 VALIDATION ACCURACY 0.666095890410959\n",
      "-------------------- Epoch 23 --------------------\n",
      "TRAIN ACCURACY 0.6461607543780871 VALIDATION ACCURACY 0.6626712328767124\n",
      "-------------------- Epoch 24 --------------------\n",
      "TRAIN ACCURACY 0.6448136506511002 VALIDATION ACCURACY 0.660958904109589\n",
      "-------------------- Epoch 25 --------------------\n",
      "TRAIN ACCURACY 0.6452626852267624 VALIDATION ACCURACY 0.6626712328767124\n",
      "-------------------- Epoch 26 --------------------\n",
      "TRAIN ACCURACY 0.6466097889537494 VALIDATION ACCURACY 0.6626712328767124\n",
      "-------------------- Epoch 27 --------------------\n",
      "TRAIN ACCURACY 0.6470588235294118 VALIDATION ACCURACY 0.6626712328767124\n",
      "-------------------- Epoch 28 --------------------\n",
      "TRAIN ACCURACY 0.6470588235294118 VALIDATION ACCURACY 0.6626712328767124\n",
      "-------------------- Epoch 29 --------------------\n",
      "TRAIN ACCURACY 0.6466097889537494 VALIDATION ACCURACY 0.666095890410959\n",
      "-------------------- Epoch 30 --------------------\n",
      "TRAIN ACCURACY 0.6470588235294118 VALIDATION ACCURACY 0.666095890410959\n",
      "-------------------- Epoch 31 --------------------\n",
      "TRAIN ACCURACY 0.6466097889537494 VALIDATION ACCURACY 0.6643835616438356\n",
      "-------------------- Epoch 32 --------------------\n",
      "TRAIN ACCURACY 0.6470588235294118 VALIDATION ACCURACY 0.6643835616438356\n",
      "-------------------- Epoch 33 --------------------\n",
      "TRAIN ACCURACY 0.647507858105074 VALIDATION ACCURACY 0.6643835616438356\n",
      "-------------------- Epoch 34 --------------------\n",
      "TRAIN ACCURACY 0.648854961832061 VALIDATION ACCURACY 0.6643835616438356\n",
      "-------------------- Epoch 35 --------------------\n",
      "TRAIN ACCURACY 0.6493039964077234 VALIDATION ACCURACY 0.6626712328767124\n",
      "-------------------- Epoch 36 --------------------\n",
      "TRAIN ACCURACY 0.6493039964077234 VALIDATION ACCURACY 0.6626712328767124\n",
      "-------------------- Epoch 37 --------------------\n",
      "TRAIN ACCURACY 0.6484059272563988 VALIDATION ACCURACY 0.6643835616438356\n",
      "-------------------- Epoch 38 --------------------\n",
      "TRAIN ACCURACY 0.6484059272563988 VALIDATION ACCURACY 0.6643835616438356\n",
      "-------------------- Epoch 39 --------------------\n",
      "TRAIN ACCURACY 0.648854961832061 VALIDATION ACCURACY 0.666095890410959\n",
      "-------------------- Epoch 40 --------------------\n",
      "TRAIN ACCURACY 0.650202065559048 VALIDATION ACCURACY 0.666095890410959\n",
      "-------------------- Epoch 41 --------------------\n",
      "TRAIN ACCURACY 0.6506511001347104 VALIDATION ACCURACY 0.6643835616438356\n",
      "-------------------- Epoch 42 --------------------\n",
      "TRAIN ACCURACY 0.6511001347103726 VALIDATION ACCURACY 0.6643835616438356\n",
      "-------------------- Epoch 43 --------------------\n",
      "TRAIN ACCURACY 0.6511001347103726 VALIDATION ACCURACY 0.6643835616438356\n",
      "-------------------- Epoch 44 --------------------\n",
      "TRAIN ACCURACY 0.6506511001347104 VALIDATION ACCURACY 0.6643835616438356\n",
      "-------------------- Epoch 45 --------------------\n",
      "TRAIN ACCURACY 0.650202065559048 VALIDATION ACCURACY 0.6643835616438356\n",
      "-------------------- Epoch 46 --------------------\n",
      "TRAIN ACCURACY 0.6506511001347104 VALIDATION ACCURACY 0.6643835616438356\n",
      "-------------------- Epoch 47 --------------------\n",
      "TRAIN ACCURACY 0.6497530309833858 VALIDATION ACCURACY 0.6678082191780822\n",
      "-------------------- Epoch 48 --------------------\n",
      "TRAIN ACCURACY 0.6506511001347104 VALIDATION ACCURACY 0.666095890410959\n",
      "-------------------- Epoch 49 --------------------\n",
      "TRAIN ACCURACY 0.6506511001347104 VALIDATION ACCURACY 0.666095890410959\n",
      "-------------------- Epoch 50 --------------------\n",
      "TRAIN ACCURACY 0.651549169286035 VALIDATION ACCURACY 0.666095890410959\n",
      "-------------------- Epoch 51 --------------------\n",
      "TRAIN ACCURACY 0.651549169286035 VALIDATION ACCURACY 0.6643835616438356\n",
      "-------------------- Epoch 52 --------------------\n",
      "TRAIN ACCURACY 0.6519982038616974 VALIDATION ACCURACY 0.6643835616438356\n",
      "-------------------- Epoch 53 --------------------\n",
      "TRAIN ACCURACY 0.6519982038616974 VALIDATION ACCURACY 0.6643835616438356\n",
      "-------------------- Epoch 54 --------------------\n",
      "TRAIN ACCURACY 0.651549169286035 VALIDATION ACCURACY 0.6643835616438356\n",
      "-------------------- Epoch 55 --------------------\n",
      "TRAIN ACCURACY 0.652896273013022 VALIDATION ACCURACY 0.6643835616438356\n",
      "-------------------- Epoch 56 --------------------\n",
      "TRAIN ACCURACY 0.652896273013022 VALIDATION ACCURACY 0.6643835616438356\n",
      "-------------------- Epoch 57 --------------------\n",
      "TRAIN ACCURACY 0.6533453075886844 VALIDATION ACCURACY 0.6643835616438356\n",
      "-------------------- Epoch 58 --------------------\n",
      "TRAIN ACCURACY 0.6533453075886844 VALIDATION ACCURACY 0.6643835616438356\n",
      "-------------------- Epoch 59 --------------------\n",
      "TRAIN ACCURACY 0.652896273013022 VALIDATION ACCURACY 0.6643835616438356\n",
      "-------------------- Epoch 60 --------------------\n",
      "TRAIN ACCURACY 0.6533453075886844 VALIDATION ACCURACY 0.6643835616438356\n",
      "-------------------- Epoch 61 --------------------\n",
      "TRAIN ACCURACY 0.6533453075886844 VALIDATION ACCURACY 0.666095890410959\n",
      "-------------------- Epoch 62 --------------------\n",
      "TRAIN ACCURACY 0.6533453075886844 VALIDATION ACCURACY 0.666095890410959\n",
      "-------------------- Epoch 63 --------------------\n",
      "TRAIN ACCURACY 0.6524472384373596 VALIDATION ACCURACY 0.666095890410959\n",
      "-------------------- Epoch 64 --------------------\n",
      "TRAIN ACCURACY 0.652896273013022 VALIDATION ACCURACY 0.666095890410959\n",
      "-------------------- Epoch 65 --------------------\n",
      "TRAIN ACCURACY 0.652896273013022 VALIDATION ACCURACY 0.666095890410959\n",
      "-------------------- Epoch 66 --------------------\n",
      "TRAIN ACCURACY 0.652896273013022 VALIDATION ACCURACY 0.666095890410959\n",
      "-------------------- Epoch 67 --------------------\n",
      "TRAIN ACCURACY 0.652896273013022 VALIDATION ACCURACY 0.666095890410959\n",
      "-------------------- Epoch 68 --------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN ACCURACY 0.6533453075886844 VALIDATION ACCURACY 0.6643835616438356\n",
      "-------------------- Epoch 69 --------------------\n",
      "TRAIN ACCURACY 0.6546924113156714 VALIDATION ACCURACY 0.6643835616438356\n",
      "-------------------- Epoch 70 --------------------\n",
      "TRAIN ACCURACY 0.6546924113156714 VALIDATION ACCURACY 0.666095890410959\n",
      "-------------------- Epoch 71 --------------------\n",
      "TRAIN ACCURACY 0.654243376740009 VALIDATION ACCURACY 0.666095890410959\n",
      "-------------------- Epoch 72 --------------------\n",
      "TRAIN ACCURACY 0.6546924113156714 VALIDATION ACCURACY 0.6643835616438356\n",
      "-------------------- Epoch 73 --------------------\n",
      "TRAIN ACCURACY 0.6551414458913336 VALIDATION ACCURACY 0.6643835616438356\n",
      "-------------------- Epoch 74 --------------------\n",
      "TRAIN ACCURACY 0.655590480466996 VALIDATION ACCURACY 0.6643835616438356\n",
      "-------------------- Epoch 75 --------------------\n",
      "TRAIN ACCURACY 0.6551414458913336 VALIDATION ACCURACY 0.6643835616438356\n",
      "-------------------- Epoch 76 --------------------\n",
      "TRAIN ACCURACY 0.6560395150426583 VALIDATION ACCURACY 0.6643835616438356\n",
      "-------------------- Epoch 77 --------------------\n",
      "TRAIN ACCURACY 0.6560395150426583 VALIDATION ACCURACY 0.666095890410959\n",
      "-------------------- Epoch 78 --------------------\n",
      "TRAIN ACCURACY 0.6560395150426583 VALIDATION ACCURACY 0.666095890410959\n",
      "-------------------- Epoch 79 --------------------\n",
      "TRAIN ACCURACY 0.6560395150426583 VALIDATION ACCURACY 0.666095890410959\n",
      "-------------------- Epoch 80 --------------------\n",
      "TRAIN ACCURACY 0.6560395150426583 VALIDATION ACCURACY 0.666095890410959\n",
      "-------------------- Epoch 81 --------------------\n",
      "TRAIN ACCURACY 0.655590480466996 VALIDATION ACCURACY 0.666095890410959\n",
      "-------------------- Epoch 82 --------------------\n",
      "TRAIN ACCURACY 0.6560395150426583 VALIDATION ACCURACY 0.666095890410959\n",
      "-------------------- Epoch 83 --------------------\n",
      "TRAIN ACCURACY 0.6560395150426583 VALIDATION ACCURACY 0.666095890410959\n",
      "-------------------- Epoch 84 --------------------\n",
      "TRAIN ACCURACY 0.655590480466996 VALIDATION ACCURACY 0.666095890410959\n",
      "-------------------- Epoch 85 --------------------\n",
      "TRAIN ACCURACY 0.6573866187696452 VALIDATION ACCURACY 0.666095890410959\n",
      "-------------------- Epoch 86 --------------------\n",
      "TRAIN ACCURACY 0.6578356533453076 VALIDATION ACCURACY 0.6678082191780822\n",
      "-------------------- Epoch 87 --------------------\n",
      "TRAIN ACCURACY 0.6596317916479569 VALIDATION ACCURACY 0.6678082191780822\n",
      "-------------------- Epoch 88 --------------------\n",
      "TRAIN ACCURACY 0.6591827570722946 VALIDATION ACCURACY 0.6678082191780822\n",
      "-------------------- Epoch 89 --------------------\n",
      "TRAIN ACCURACY 0.6596317916479569 VALIDATION ACCURACY 0.6678082191780822\n",
      "-------------------- Epoch 90 --------------------\n",
      "TRAIN ACCURACY 0.6600808262236192 VALIDATION ACCURACY 0.6695205479452054\n",
      "-------------------- Epoch 91 --------------------\n",
      "TRAIN ACCURACY 0.6600808262236192 VALIDATION ACCURACY 0.6678082191780822\n",
      "-------------------- Epoch 92 --------------------\n",
      "TRAIN ACCURACY 0.6600808262236192 VALIDATION ACCURACY 0.666095890410959\n",
      "-------------------- Epoch 93 --------------------\n",
      "TRAIN ACCURACY 0.6614279299506062 VALIDATION ACCURACY 0.666095890410959\n",
      "-------------------- Epoch 94 --------------------\n",
      "TRAIN ACCURACY 0.6618769645262685 VALIDATION ACCURACY 0.666095890410959\n",
      "-------------------- Epoch 95 --------------------\n",
      "TRAIN ACCURACY 0.6618769645262685 VALIDATION ACCURACY 0.6678082191780822\n",
      "-------------------- Epoch 96 --------------------\n",
      "TRAIN ACCURACY 0.6618769645262685 VALIDATION ACCURACY 0.666095890410959\n",
      "-------------------- Epoch 97 --------------------\n",
      "TRAIN ACCURACY 0.6614279299506062 VALIDATION ACCURACY 0.666095890410959\n",
      "-------------------- Epoch 98 --------------------\n",
      "TRAIN ACCURACY 0.6618769645262685 VALIDATION ACCURACY 0.666095890410959\n",
      "-------------------- Epoch 99 --------------------\n",
      "TRAIN ACCURACY 0.6618769645262685 VALIDATION ACCURACY 0.666095890410959\n",
      "-------------------- Epoch 100 --------------------\n",
      "TRAIN ACCURACY 0.6623259991019308 VALIDATION ACCURACY 0.666095890410959\n",
      "-------------------- Epoch 101 --------------------\n",
      "TRAIN ACCURACY 0.6632240682532555 VALIDATION ACCURACY 0.666095890410959\n",
      "-------------------- Epoch 102 --------------------\n",
      "TRAIN ACCURACY 0.6627750336775932 VALIDATION ACCURACY 0.666095890410959\n",
      "-------------------- Epoch 103 --------------------\n",
      "TRAIN ACCURACY 0.6627750336775932 VALIDATION ACCURACY 0.666095890410959\n",
      "-------------------- Epoch 104 --------------------\n",
      "TRAIN ACCURACY 0.6627750336775932 VALIDATION ACCURACY 0.666095890410959\n",
      "-------------------- Epoch 105 --------------------\n",
      "TRAIN ACCURACY 0.6627750336775932 VALIDATION ACCURACY 0.666095890410959\n",
      "-------------------- Epoch 106 --------------------\n",
      "TRAIN ACCURACY 0.6623259991019308 VALIDATION ACCURACY 0.6695205479452054\n",
      "-------------------- Epoch 107 --------------------\n",
      "TRAIN ACCURACY 0.6632240682532555 VALIDATION ACCURACY 0.6695205479452054\n",
      "-------------------- Epoch 108 --------------------\n",
      "TRAIN ACCURACY 0.6627750336775932 VALIDATION ACCURACY 0.6626712328767124\n",
      "-------------------- Epoch 109 --------------------\n",
      "TRAIN ACCURACY 0.6632240682532555 VALIDATION ACCURACY 0.6626712328767124\n",
      "-------------------- Epoch 110 --------------------\n",
      "TRAIN ACCURACY 0.6636731028289178 VALIDATION ACCURACY 0.6626712328767124\n",
      "-------------------- Epoch 111 --------------------\n",
      "TRAIN ACCURACY 0.6632240682532555 VALIDATION ACCURACY 0.6626712328767124\n",
      "-------------------- Epoch 112 --------------------\n",
      "TRAIN ACCURACY 0.6632240682532555 VALIDATION ACCURACY 0.6626712328767124\n",
      "-------------------- Epoch 113 --------------------\n",
      "TRAIN ACCURACY 0.6636731028289178 VALIDATION ACCURACY 0.6626712328767124\n",
      "-------------------- Epoch 114 --------------------\n",
      "TRAIN ACCURACY 0.6632240682532555 VALIDATION ACCURACY 0.6626712328767124\n",
      "-------------------- Epoch 115 --------------------\n",
      "TRAIN ACCURACY 0.6654692411315671 VALIDATION ACCURACY 0.6626712328767124\n",
      "-------------------- Epoch 116 --------------------\n",
      "TRAIN ACCURACY 0.6654692411315671 VALIDATION ACCURACY 0.6626712328767124\n",
      "-------------------- Epoch 117 --------------------\n",
      "TRAIN ACCURACY 0.6659182757072295 VALIDATION ACCURACY 0.6678082191780822\n",
      "-------------------- Epoch 118 --------------------\n",
      "TRAIN ACCURACY 0.6672653794342165 VALIDATION ACCURACY 0.6678082191780822\n",
      "-------------------- Epoch 119 --------------------\n",
      "TRAIN ACCURACY 0.6677144140098787 VALIDATION ACCURACY 0.6695205479452054\n",
      "-------------------- Epoch 120 --------------------\n",
      "TRAIN ACCURACY 0.6677144140098787 VALIDATION ACCURACY 0.6695205479452054\n",
      "-------------------- Epoch 121 --------------------\n",
      "TRAIN ACCURACY 0.6677144140098787 VALIDATION ACCURACY 0.6695205479452054\n",
      "-------------------- Epoch 122 --------------------\n",
      "TRAIN ACCURACY 0.6654692411315671 VALIDATION ACCURACY 0.6678082191780822\n",
      "-------------------- Epoch 123 --------------------\n",
      "TRAIN ACCURACY 0.6650202065559048 VALIDATION ACCURACY 0.666095890410959\n",
      "-------------------- Epoch 124 --------------------\n",
      "TRAIN ACCURACY 0.6659182757072295 VALIDATION ACCURACY 0.6678082191780822\n",
      "-------------------- Epoch 125 --------------------\n",
      "TRAIN ACCURACY 0.6663673102828918 VALIDATION ACCURACY 0.6678082191780822\n",
      "-------------------- Epoch 126 --------------------\n",
      "TRAIN ACCURACY 0.6659182757072295 VALIDATION ACCURACY 0.6678082191780822\n",
      "-------------------- Epoch 127 --------------------\n",
      "TRAIN ACCURACY 0.6659182757072295 VALIDATION ACCURACY 0.6678082191780822\n",
      "-------------------- Epoch 128 --------------------\n",
      "TRAIN ACCURACY 0.6654692411315671 VALIDATION ACCURACY 0.6678082191780822\n",
      "-------------------- Epoch 129 --------------------\n",
      "TRAIN ACCURACY 0.6654692411315671 VALIDATION ACCURACY 0.6678082191780822\n",
      "-------------------- Epoch 130 --------------------\n",
      "TRAIN ACCURACY 0.6659182757072295 VALIDATION ACCURACY 0.6695205479452054\n",
      "-------------------- Epoch 131 --------------------\n",
      "TRAIN ACCURACY 0.6668163448585541 VALIDATION ACCURACY 0.6712328767123288\n",
      "-------------------- Epoch 132 --------------------\n",
      "TRAIN ACCURACY 0.6663673102828918 VALIDATION ACCURACY 0.6695205479452054\n",
      "-------------------- Epoch 133 --------------------\n",
      "TRAIN ACCURACY 0.6663673102828918 VALIDATION ACCURACY 0.6695205479452054\n",
      "-------------------- Epoch 134 --------------------\n",
      "TRAIN ACCURACY 0.6663673102828918 VALIDATION ACCURACY 0.6678082191780822\n",
      "-------------------- Epoch 135 --------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN ACCURACY 0.6668163448585541 VALIDATION ACCURACY 0.6678082191780822\n",
      "-------------------- Epoch 136 --------------------\n",
      "TRAIN ACCURACY 0.6654692411315671 VALIDATION ACCURACY 0.6678082191780822\n",
      "-------------------- Epoch 137 --------------------\n",
      "TRAIN ACCURACY 0.6659182757072295 VALIDATION ACCURACY 0.6678082191780822\n",
      "-------------------- Epoch 138 --------------------\n",
      "TRAIN ACCURACY 0.6663673102828918 VALIDATION ACCURACY 0.6695205479452054\n",
      "-------------------- Epoch 139 --------------------\n",
      "TRAIN ACCURACY 0.6672653794342165 VALIDATION ACCURACY 0.6712328767123288\n",
      "-------------------- Epoch 140 --------------------\n",
      "TRAIN ACCURACY 0.6690615177368657 VALIDATION ACCURACY 0.672945205479452\n",
      "-------------------- Epoch 141 --------------------\n",
      "TRAIN ACCURACY 0.6690615177368657 VALIDATION ACCURACY 0.672945205479452\n",
      "-------------------- Epoch 142 --------------------\n",
      "TRAIN ACCURACY 0.6690615177368657 VALIDATION ACCURACY 0.6695205479452054\n",
      "-------------------- Epoch 143 --------------------\n",
      "TRAIN ACCURACY 0.6695105523125281 VALIDATION ACCURACY 0.6695205479452054\n",
      "-------------------- Epoch 144 --------------------\n",
      "TRAIN ACCURACY 0.6699595868881904 VALIDATION ACCURACY 0.6678082191780822\n",
      "-------------------- Epoch 145 --------------------\n",
      "TRAIN ACCURACY 0.6708576560395151 VALIDATION ACCURACY 0.6695205479452054\n",
      "-------------------- Epoch 146 --------------------\n",
      "TRAIN ACCURACY 0.6704086214638527 VALIDATION ACCURACY 0.6695205479452054\n",
      "-------------------- Epoch 147 --------------------\n",
      "TRAIN ACCURACY 0.6731028289178267 VALIDATION ACCURACY 0.6678082191780822\n",
      "-------------------- Epoch 148 --------------------\n",
      "TRAIN ACCURACY 0.6731028289178267 VALIDATION ACCURACY 0.6695205479452054\n",
      "-------------------- Epoch 149 --------------------\n",
      "TRAIN ACCURACY 0.6731028289178267 VALIDATION ACCURACY 0.6695205479452054\n",
      "-------------------- Epoch 150 --------------------\n",
      "TRAIN ACCURACY 0.6722047597665021 VALIDATION ACCURACY 0.6695205479452054\n",
      "-------------------- Epoch 151 --------------------\n",
      "TRAIN ACCURACY 0.6717557251908397 VALIDATION ACCURACY 0.6678082191780822\n",
      "-------------------- Epoch 152 --------------------\n",
      "TRAIN ACCURACY 0.6708576560395151 VALIDATION ACCURACY 0.6643835616438356\n",
      "-------------------- Epoch 153 --------------------\n",
      "TRAIN ACCURACY 0.6708576560395151 VALIDATION ACCURACY 0.6643835616438356\n",
      "-------------------- Epoch 154 --------------------\n",
      "TRAIN ACCURACY 0.6704086214638527 VALIDATION ACCURACY 0.6643835616438356\n",
      "-------------------- Epoch 155 --------------------\n",
      "TRAIN ACCURACY 0.6699595868881904 VALIDATION ACCURACY 0.6643835616438356\n",
      "-------------------- Epoch 156 --------------------\n",
      "TRAIN ACCURACY 0.6695105523125281 VALIDATION ACCURACY 0.6643835616438356\n",
      "-------------------- Epoch 157 --------------------\n",
      "TRAIN ACCURACY 0.6704086214638527 VALIDATION ACCURACY 0.6643835616438356\n",
      "-------------------- Epoch 158 --------------------\n",
      "TRAIN ACCURACY 0.6704086214638527 VALIDATION ACCURACY 0.666095890410959\n",
      "-------------------- Epoch 159 --------------------\n",
      "TRAIN ACCURACY 0.6704086214638527 VALIDATION ACCURACY 0.666095890410959\n",
      "-------------------- Epoch 160 --------------------\n",
      "TRAIN ACCURACY 0.6708576560395151 VALIDATION ACCURACY 0.666095890410959\n",
      "-------------------- Epoch 161 --------------------\n",
      "TRAIN ACCURACY 0.6699595868881904 VALIDATION ACCURACY 0.666095890410959\n",
      "-------------------- Epoch 162 --------------------\n",
      "TRAIN ACCURACY 0.6681634485855411 VALIDATION ACCURACY 0.6678082191780822\n",
      "-------------------- Epoch 163 --------------------\n",
      "TRAIN ACCURACY 0.6686124831612034 VALIDATION ACCURACY 0.6678082191780822\n",
      "-------------------- Epoch 164 --------------------\n",
      "TRAIN ACCURACY 0.6690615177368657 VALIDATION ACCURACY 0.6695205479452054\n",
      "-------------------- Epoch 165 --------------------\n",
      "TRAIN ACCURACY 0.6690615177368657 VALIDATION ACCURACY 0.6712328767123288\n",
      "-------------------- Epoch 166 --------------------\n",
      "TRAIN ACCURACY 0.6695105523125281 VALIDATION ACCURACY 0.6678082191780822\n",
      "-------------------- Epoch 167 --------------------\n",
      "TRAIN ACCURACY 0.6681634485855411 VALIDATION ACCURACY 0.666095890410959\n",
      "-------------------- Epoch 168 --------------------\n",
      "TRAIN ACCURACY 0.6677144140098787 VALIDATION ACCURACY 0.666095890410959\n",
      "-------------------- Epoch 169 --------------------\n",
      "TRAIN ACCURACY 0.6681634485855411 VALIDATION ACCURACY 0.6678082191780822\n",
      "-------------------- Epoch 170 --------------------\n",
      "TRAIN ACCURACY 0.6681634485855411 VALIDATION ACCURACY 0.6695205479452054\n",
      "-------------------- Epoch 171 --------------------\n",
      "TRAIN ACCURACY 0.6677144140098787 VALIDATION ACCURACY 0.6678082191780822\n",
      "-------------------- Epoch 172 --------------------\n",
      "TRAIN ACCURACY 0.6677144140098787 VALIDATION ACCURACY 0.666095890410959\n",
      "-------------------- Epoch 173 --------------------\n",
      "TRAIN ACCURACY 0.6672653794342165 VALIDATION ACCURACY 0.666095890410959\n",
      "-------------------- Epoch 174 --------------------\n",
      "TRAIN ACCURACY 0.6672653794342165 VALIDATION ACCURACY 0.6678082191780822\n",
      "-------------------- Epoch 175 --------------------\n",
      "TRAIN ACCURACY 0.6672653794342165 VALIDATION ACCURACY 0.6678082191780822\n",
      "-------------------- Epoch 176 --------------------\n",
      "TRAIN ACCURACY 0.6672653794342165 VALIDATION ACCURACY 0.6678082191780822\n",
      "-------------------- Epoch 177 --------------------\n",
      "TRAIN ACCURACY 0.6681634485855411 VALIDATION ACCURACY 0.6678082191780822\n",
      "-------------------- Epoch 178 --------------------\n",
      "TRAIN ACCURACY 0.6677144140098787 VALIDATION ACCURACY 0.6678082191780822\n",
      "-------------------- Epoch 179 --------------------\n",
      "TRAIN ACCURACY 0.6672653794342165 VALIDATION ACCURACY 0.6695205479452054\n",
      "-------------------- Epoch 180 --------------------\n",
      "TRAIN ACCURACY 0.6677144140098787 VALIDATION ACCURACY 0.6695205479452054\n",
      "-------------------- Epoch 181 --------------------\n",
      "TRAIN ACCURACY 0.6677144140098787 VALIDATION ACCURACY 0.6695205479452054\n",
      "-------------------- Epoch 182 --------------------\n",
      "TRAIN ACCURACY 0.6681634485855411 VALIDATION ACCURACY 0.6695205479452054\n",
      "-------------------- Epoch 183 --------------------\n",
      "TRAIN ACCURACY 0.6681634485855411 VALIDATION ACCURACY 0.6695205479452054\n",
      "-------------------- Epoch 184 --------------------\n",
      "TRAIN ACCURACY 0.6677144140098787 VALIDATION ACCURACY 0.6695205479452054\n",
      "-------------------- Epoch 185 --------------------\n",
      "TRAIN ACCURACY 0.6677144140098787 VALIDATION ACCURACY 0.6695205479452054\n",
      "-------------------- Epoch 186 --------------------\n",
      "TRAIN ACCURACY 0.6677144140098787 VALIDATION ACCURACY 0.6695205479452054\n",
      "-------------------- Epoch 187 --------------------\n",
      "TRAIN ACCURACY 0.6677144140098787 VALIDATION ACCURACY 0.6695205479452054\n",
      "-------------------- Epoch 188 --------------------\n",
      "TRAIN ACCURACY 0.6686124831612034 VALIDATION ACCURACY 0.6695205479452054\n",
      "-------------------- Epoch 189 --------------------\n",
      "TRAIN ACCURACY 0.6681634485855411 VALIDATION ACCURACY 0.6695205479452054\n",
      "-------------------- Epoch 190 --------------------\n",
      "TRAIN ACCURACY 0.6681634485855411 VALIDATION ACCURACY 0.6695205479452054\n",
      "-------------------- Epoch 191 --------------------\n",
      "TRAIN ACCURACY 0.6690615177368657 VALIDATION ACCURACY 0.6695205479452054\n",
      "-------------------- Epoch 192 --------------------\n",
      "TRAIN ACCURACY 0.6686124831612034 VALIDATION ACCURACY 0.6695205479452054\n",
      "-------------------- Epoch 193 --------------------\n",
      "TRAIN ACCURACY 0.6690615177368657 VALIDATION ACCURACY 0.6695205479452054\n",
      "-------------------- Epoch 194 --------------------\n",
      "TRAIN ACCURACY 0.6690615177368657 VALIDATION ACCURACY 0.6695205479452054\n",
      "-------------------- Epoch 195 --------------------\n",
      "TRAIN ACCURACY 0.6695105523125281 VALIDATION ACCURACY 0.6678082191780822\n",
      "-------------------- Epoch 196 --------------------\n",
      "TRAIN ACCURACY 0.6695105523125281 VALIDATION ACCURACY 0.6678082191780822\n",
      "-------------------- Epoch 197 --------------------\n",
      "TRAIN ACCURACY 0.6708576560395151 VALIDATION ACCURACY 0.6678082191780822\n",
      "-------------------- Epoch 198 --------------------\n",
      "TRAIN ACCURACY 0.6708576560395151 VALIDATION ACCURACY 0.6678082191780822\n",
      "-------------------- Epoch 199 --------------------\n",
      "TRAIN ACCURACY 0.6699595868881904 VALIDATION ACCURACY 0.6678082191780822\n",
      "-------------------- Epoch 200 --------------------\n",
      "TRAIN ACCURACY 0.6699595868881904 VALIDATION ACCURACY 0.6678082191780822\n"
     ]
    }
   ],
   "source": [
    "#Start training\n",
    "train(trn_ds, trn_dl, epochs=200)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
